# precompute_metrics.py
import os
import pandas as pd
import numpy as np
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, util

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
ABOUT_COL = "–ö–æ—Ä–æ—Ç–∫–æ –æ —Å–µ–±–µ"
COMPARE_COLS = ["–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏", "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞", "–†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏"]

INPUT_FILES = [
    "–ü—Ä–æ—Ñ–∏–ª–∏_–í–≠–°.xlsx",
    "–ü—Ä–æ—Ñ–∏–ª–∏_–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã.xlsx",
    "–ü—Ä–æ—Ñ–∏–ª–∏_—ç–∫—Å–ø–µ—Ä—Ç—ã.xlsx",
]

OUTPUT_PARQUET = "profiles_with_metrics.parquet"
OUTPUT_EXCEL = "profiles_with_metrics.xlsx"

# === –®–∞–≥ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ ===
print("üîπ Loading data...")
frames = []
for file in INPUT_FILES:
    if os.path.exists(file):
        frames.append(pd.read_excel(file))
if not frames:
    raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π!")

df = pd.concat(frames, ignore_index=True).drop_duplicates()
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# === –®–∞–≥ 2. –ú–æ–¥–µ–ª—å ===
print("üîπ Loading sentence-transformer model...")
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# === –®–∞–≥ 3. –ü—Ä–µ–¥—Ä–∞—Å—á—ë—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ===
print("üîπ Encoding '–ö–æ—Ä–æ—Ç–∫–æ –æ —Å–µ–±–µ'...")
mask = df[ABOUT_COL].notna() & (df[ABOUT_COL].astype(str).str.len() >= 5)
about_texts = df.loc[mask, ABOUT_COL].astype(str).tolist()
about_embs = model.encode(about_texts, convert_to_tensor=True, show_progress_bar=True)
idx_map = {idx: i for i, idx in enumerate(df.index[mask])}

# === –®–∞–≥ 4. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ===
sim_cols = []
print("üîπ Computing semantic similarities...")
for col in COMPARE_COLS:
    sims = []
    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"Processing {col}"):
        if not mask[idx]:
            sims.append(np.nan)
            continue
        other = row.get(col, None)
        if pd.isna(other) or len(str(other)) < 3:
            sims.append(np.nan)
            continue
        emb_other = model.encode(str(other), convert_to_tensor=True)
        emb_about = about_embs[idx_map[idx]]
        sims.append(float(util.cos_sim(emb_about, emb_other)))
    cname = f"sim_{col}"
    df[cname] = sims
    sim_cols.append(cname)

# === –®–∞–≥ 5. PTA –∏ –∫–æ–≥–æ—Ä—Ç—ã ===
df["PTA"] = df[sim_cols].mean(axis=1)

def define_cohort(pta):
    if pd.isna(pta):
        return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"
    if pta < 0.40:
        return "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)"
    if pta < 0.60:
        return "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)"
    return "–í—ã—Å–æ–∫–∏–π (–û–ö)"

df["–ö–æ–≥–æ—Ä—Ç–∞"] = df["PTA"].apply(define_cohort)

# === –®–∞–≥ 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===
print("üíæ Saving precomputed metrics...")
df.to_parquet(OUTPUT_PARQUET, index=False)
df.to_excel(OUTPUT_EXCEL, index=False)
print(f"‚úÖ Done! Saved {OUTPUT_PARQUET} and {OUTPUT_EXCEL}")