# -*- coding: utf-8 -*-
# –ë–ò–ó–ù–ï–°-–î–ê–®–ë–û–†–î: –æ—Ü–µ–Ω–∏–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ "–û —Å–µ–±–µ" —Ç–æ–ª—å–∫–æ —Å —Ç—Ä–µ–º—è –ø–æ–ª—è–º–∏:
# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏.

import os
import io
import math
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

# ------------------------- PAGE CONFIG (–ø–µ—Ä–≤–∞—è st-–∫–æ–º–∞–Ω–¥–∞!) -------------------
st.set_page_config(page_title="–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —à—Ç–∞—Ç: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π", layout="wide")

# ------------------------- CONFIG ---------------------------------------------
# –£–∫–∞–∂–∏ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
FILE_PATHS = [
    "–ü—Ä–æ—Ñ–∏–ª–∏_–í–≠–°.xlsx",
    "–ü—Ä–æ—Ñ–∏–ª–∏_–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã.xlsx",
    "–ü—Ä–æ—Ñ–∏–ª–∏_—ç–∫—Å–ø–µ—Ä—Ç—ã.xlsx",
]

AUTO_DISCOVER = False
SEARCH_DIR = "/Users/karimalibekov/Desktop/stat_consult_analysis"

ABOUT_COL = "–ö–æ—Ä–æ—Ç–∫–æ –æ —Å–µ–±–µ"

# –í —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –≤–∫–ª—é—á–∞–µ–º –¢–û–õ–¨–ö–û —ç—Ç–∏ —Ç—Ä–∏ –ø–æ–ª—è
COMPARE_COLS = ["–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏", "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞", "–†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏"]

# —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
METRIC_LABELS = {
    "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏": "Specialty Fit",
    "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞": "Keyword Fit",
    "–†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏": "Task Fit",
}

ID_CANDIDATES = ["–§–ò–û", "–§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ", "–ò–º—è", "–§–∞–º–∏–ª–∏—è –∏ –ò–º—è", "–§–ò–û –ø–æ–ª–Ω–æ—Å—Ç—å—é"]

# –ü–æ—Ä–æ–≥–∏ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
LOW_THR = 0.40       # –Ω–∏–∂–µ ‚Äî "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)"
HIGH_THR = 0.60      # –≤—ã—à–µ ‚Äî "–í—ã—Å–æ–∫–∏–π (–û–ö)"
TARGET_PTA = 0.65    # —Ü–µ–ª–µ–≤–æ–π —Å—Ä–µ–¥–Ω–∏–π PTA –∫–æ–º–ø–∞–Ω–∏–∏ (–¥–ª—è KPI)

# ------------------------- HELPERS --------------------------------------------
def discover_files(folder: str):
    if not os.path.isdir(folder):
        return []
    return sorted([
        os.path.join(folder, name)
        for name in os.listdir(folder)
        if name.startswith("–ü—Ä–æ—Ñ–∏–ª–∏_") and name.endswith(".xlsx")
    ])

@st.cache_data(show_spinner=True)
def load_all(paths):
    frames = []
    for p in paths:
        if not os.path.exists(p):
            st.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {p}")
            continue
        try:
            df = pd.read_excel(p)
            df["__source"] = os.path.basename(p)
            frames.append(df)
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {p}: {e}")
    if not frames:
        return pd.DataFrame()
    df = pd.concat(frames, ignore_index=True)
    # –±–∞–∑–æ–≤–∞—è —á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    df = df.drop_duplicates()
    return df

def pick_id_col(df: pd.DataFrame):
    for c in ID_CANDIDATES:
        if c in df.columns:
            return c
    return df.columns[0]

@st.cache_resource(show_spinner=True)
def load_model():
    from sentence_transformers import SentenceTransformer
    return SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

@st.cache_data(show_spinner=True)
def compute_similarities(df_in: pd.DataFrame, about_col: str, compare_cols: list) -> pd.DataFrame:
    """
    –°—á–∏—Ç–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω—ã–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ '–ö–æ—Ä–æ—Ç–∫–æ –æ —Å–µ–±–µ' –∏ —Ç—Ä–µ–º—è –ø–æ–ª—è–º–∏:
    '–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏', '–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞', '–†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏'.
    PTA = —Å—Ä–µ–¥–Ω–µ–µ —ç—Ç–∏—Ö —Ç—Ä–µ—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Å—Ç–æ–ª–±—Ü–∞–º.
    """
    from sentence_transformers import util

    df = df_in.copy()
    sim_cols = []

    # –µ—Å–ª–∏ –Ω–µ—Ç about ‚Äî –≤–µ—Ä–Ω–µ–º –ø—É—Å—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if about_col not in df.columns:
        for c in compare_cols:
            df[f"sim_{c}"] = np.nan
        df["PTA"] = np.nan
        return df

    model = load_model()

    # –≤–∞–ª–∏–¥–Ω—ã–µ "–û —Å–µ–±–µ"
    mask = df[about_col].notna() & (df[about_col].astype(str).str.len() >= 5)
    df["_has_about"] = mask

    about_texts = df.loc[mask, about_col].astype(str).tolist()
    if len(about_texts) == 0:
        for c in compare_cols:
            df[f"sim_{c}"] = np.nan
        df["PTA"] = np.nan
        return df

    about_embs = model.encode(about_texts, convert_to_tensor=True, show_progress_bar=True)
    idx_map = {idx: i for i, idx in enumerate(df.index[df["_has_about"]])}

    # –ø–æ –∫–∞–∂–¥–æ–º—É –∏–∑ —Ç—Ä–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
    for col in compare_cols:
        values = []
        for idx, row in df.iterrows():
            if not row["_has_about"]:
                values.append(np.nan)
                continue
            other = row.get(col, None)
            if pd.isna(other) or len(str(other)) < 3:
                values.append(np.nan)
                continue
            emb_other = model.encode(str(other), convert_to_tensor=True)
            emb_about = about_embs[idx_map[idx]]
            cos = float(util.cos_sim(emb_about, emb_other))
            values.append(cos)
        sim_name = f"sim_{col}"
        df[sim_name] = values
        sim_cols.append(sim_name)

    # PTA = —Å—Ä–µ–¥–Ω–µ–µ –ø–æ —Ç—Ä–µ–º sim_* (–ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º)
    df["PTA"] = df[sim_cols].mean(axis=1)
    return df

def cohort_label(pta: float) -> str:
    if pd.isna(pta): return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"
    if pta < LOW_THR: return "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)"
    if pta < HIGH_THR: return "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)"
    return "–í—ã—Å–æ–∫–∏–π (–û–ö)"

def to_excel_bytes(df: pd.DataFrame, sheet_name: str = "data") -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    buf.seek(0)
    return buf.read()

def fmt_pct(x):
    try:
        return f"{x:.0%}"
    except:
        return "‚Äî"

def safe_mean(series):
    return float(series.mean()) if len(series) else float("nan")

# ------------------------- LOAD DATA ------------------------------------------
if AUTO_DISCOVER:
    FILE_PATHS = discover_files(SEARCH_DIR)

df_raw = load_all(FILE_PATHS)
if df_raw.empty:
    st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç–∏ –∫ Excel –∏–ª–∏ –≤–∫–ª—é—á–∏ AUTO_DISCOVER.")
    st.stop()

ID_COL = pick_id_col(df_raw)

# –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑ —Ç—Ä–µ—Ö –Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
compare_cols = [c for c in COMPARE_COLS if c in df_raw.columns]
missing = [c for c in COMPARE_COLS if c not in df_raw.columns]
if missing:
    st.warning("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã (–Ω–µ –±—É–¥—É—Ç —É—á—Ç–µ–Ω—ã –≤ —Ä–∞—Å—á–µ—Ç–µ): " + ", ".join(missing))

with st.spinner("–°—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ '–û —Å–µ–±–µ' —Å —Ñ–∞–∫—Ç–∞–º–∏ –ø–æ 3 –º–µ—Ç—Ä–∏–∫–∞–º‚Ä¶"):
    df = compute_similarities(df_raw, ABOUT_COL, compare_cols)

df["–ö–æ–≥–æ—Ä—Ç–∞"] = df["PTA"].apply(cohort_label)

# –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞: —Å–ø–∏—Å–æ–∫ sim_* –∫–æ–ª–æ–Ω–æ–∫ –∏ –º–∞–ø–ø–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫
sim_cols_present = [f"sim_{c}" for c in compare_cols]
metric_names = [METRIC_LABELS[c] for c in compare_cols]

# ------------------------- SIDEBAR FILTERS ------------------------------------
st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")
role_vals = ["–í—Å–µ"] + (sorted(df["–†–æ–ª—å"].dropna().unique().tolist()) if "–†–æ–ª—å" in df.columns else [])
city_vals = ["–í—Å–µ"] + (sorted(df["–ì–æ—Ä–æ–¥"].dropna().unique().tolist()) if "–ì–æ—Ä–æ–¥" in df.columns else [])

sel_role = st.sidebar.selectbox("–†–æ–ª—å", role_vals, index=0)
sel_city = st.sidebar.selectbox("–ì–æ—Ä–æ–¥", city_vals, index=0)

data = df.copy()
if "–†–æ–ª—å" in data.columns and sel_role != "–í—Å–µ":
    data = data[data["–†–æ–ª—å"] == sel_role]
if "–ì–æ—Ä–æ–¥" in data.columns and sel_city != "–í—Å–µ":
    data = data[data["–ì–æ—Ä–æ–¥"] == sel_city]

# ------------------------- HEADER ---------------------------------------------
st.markdown("## –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏ (–±–∏–∑–Ω–µ—Å-–¥–∞—à–±–æ—Ä–¥)")
st.caption(
    "–û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Äú–û —Å–µ–±–µ‚Äù —Ç–æ–ª—å–∫–æ —Å **—Ç—Ä–µ–º—è –∫–ª—é—á–µ–≤—ã–º–∏ –ø–æ–ª—è–º–∏**: "
    "–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (Specialty Fit), –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (Keyword Fit) –∏ –†–µ—à–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏ (Task Fit). "
    "PTA = —Å—Ä–µ–¥–Ω–µ–µ —ç—Ç–∏—Ö —Ç—Ä–µ—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π. "
    "–ö–æ–≥–æ—Ä—Ç—ã: **–í—ã—Å–æ–∫–∏–π (–û–ö)** ‚â• 0.60, **–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)** 0.40‚Äì0.59, **–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)** < 0.40."
)

# ------------------------- TABS -----------------------------------------------
tab1, tab2, tab3 = st.tabs([
    "Executive Overview",
    "Risk & Actions",
    "People Ops",
])

# ========================= TAB 1: EXECUTIVE OVERVIEW ==========================
with tab1:
    c1, c2, c3, c4 = st.columns(4)
    overall_pta = safe_mean(data["PTA"])
    share_high = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–í—ã—Å–æ–∫–∏–π (–û–ö)").mean() if len(data) else 0
    share_mid  = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)").mean() if len(data) else 0
    share_low  = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)").mean() if len(data) else 0

    c1.metric("–°—Ä–µ–¥–Ω–∏–π PTA (3 –º–µ—Ç—Ä–∏–∫–∏)", f"{overall_pta:.3f}" if not math.isnan(overall_pta) else "‚Äî",
              delta=f"–¶–µ–ª—å: {TARGET_PTA:.2f}")
    c2.metric("% –í—ã—Å–æ–∫–∏–π (–û–ö)", fmt_pct(share_high))
    c3.metric("% –°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)", fmt_pct(share_mid))
    c4.metric("% –ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)", fmt_pct(share_low))

    st.markdown("---")
    left, right = st.columns([1,1])

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–≥–æ—Ä—Ç
    with left:
        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º")
        if len(data):
            coh = (data["–ö–æ–≥–æ—Ä—Ç–∞"]
                   .value_counts()
                   .reindex(["–í—ã—Å–æ–∫–∏–π (–û–ö)", "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)", "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)"])
                   .fillna(0)
                   .reset_index())
            coh.columns = ["–ö–æ–≥–æ—Ä—Ç–∞", "–ö–æ–ª-–≤–æ"]
            st.plotly_chart(px.pie(coh, values="–ö–æ–ª-–≤–æ", names="–ö–æ–≥–æ—Ä—Ç–∞", hole=0.45),
                            use_container_width=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã.")

    # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ç—Ä–µ–º –º–µ—Ç—Ä–∏–∫–∞–º (—á—Ç–æ —Å–ª–∞–±–µ–µ/—Å–∏–ª—å–Ω–µ–µ)
    with right:
        st.subheader("–ì–¥–µ —Å–∏–ª—å–Ω–µ–µ/—Å–ª–∞–±–µ–µ (—Å—Ä–µ–¥–Ω–∏–µ –ø–æ 3 –º–µ—Ç—Ä–∏–∫–∞–º)")
        if sim_cols_present:
            bar_df = data[sim_cols_present].mean().reset_index()
            bar_df.columns = ["–ö–æ–ª–æ–Ω–∫–∞", "–°—Ä–µ–¥–Ω–µ–µ"]
            # –∑–∞–º–µ–Ω–∏–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–º–µ–Ω–∞ –Ω–∞ –±–∏–∑–Ω–µ—Å-–ª–µ–π–±–ª—ã
            bar_df["–ú–µ—Ç—Ä–∏–∫–∞"] = bar_df["–ö–æ–ª–æ–Ω–∫–∞"].str.replace("sim_", "", regex=False).map(METRIC_LABELS)
            bar_df = bar_df.sort_values("–°—Ä–µ–¥–Ω–µ–µ", ascending=False)
            st.plotly_chart(px.bar(bar_df, x="–ú–µ—Ç—Ä–∏–∫–∞", y="–°—Ä–µ–¥–Ω–µ–µ"), use_container_width=True)
        else:
            st.info("–ù–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ (sim_*). –ü—Ä–æ–≤–µ—Ä—å –≤—Ö–æ–¥–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã.")

    # –†–∞–∑—Ä–µ–∑ –ø–æ —Ä–æ–ª—è–º
    st.subheader("PTA –ø–æ —Ä–æ–ª—è–º (—Ç–æ–ø-10)")
    if "–†–æ–ª—å" in data.columns and len(data):
        role_df = (data.groupby("–†–æ–ª—å", as_index=False)["PTA"]
                   .mean().sort_values("PTA", ascending=False).head(10))
        st.plotly_chart(px.bar(role_df, x="–†–æ–ª—å", y="PTA"), use_container_width=True)
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–æ–ª—è–º.")

    # –†–∞–∑—Ä–µ–∑ –ø–æ –≥–æ—Ä–æ–¥–∞–º
    st.subheader("PTA –ø–æ –≥–æ—Ä–æ–¥–∞–º (—Ç–æ–ø-10)")
    if "–ì–æ—Ä–æ–¥" in data.columns and len(data):
        city_df = (data.groupby("–ì–æ—Ä–æ–¥", as_index=False)["PTA"]
                   .mean().sort_values("PTA", ascending=False).head(10))
        st.plotly_chart(px.bar(city_df, x="–ì–æ—Ä–æ–¥", y="PTA"), use_container_width=True)
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥–æ—Ä–æ–¥–∞–º.")

    # –ê–≤—Ç–æ-–≤—ã–≤–æ–¥—ã
    st.markdown("### üß© –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã")
    bullets = []
    if not math.isnan(overall_pta):
        bullets.append(f"- –°—Ä–µ–¥–Ω–∏–π PTA (–ø–æ 3 –º–µ—Ç—Ä–∏–∫–∞–º): **{overall_pta:.2f}** (—Ü–µ–ª—å: **{TARGET_PTA:.2f}**).")
    bullets.append(f"- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–≥–æ—Ä—Ç: **–û–ö** {fmt_pct(share_high)}, **–í–Ω–∏–º–∞–Ω–∏–µ** {fmt_pct(share_mid)}, **–ò—Å–ø—Ä–∞–≤–∏—Ç—å** {fmt_pct(share_low)}.")
    if sim_cols_present:
        means_map = {METRIC_LABELS[c]: data[f"sim_{c}"].mean() for c in compare_cols}
        weakest = min(means_map, key=means_map.get) if means_map else None
        strongest = max(means_map, key=means_map.get) if means_map else None
        if weakest:
            bullets.append(f"- –°–ª–∞–±–µ–µ –≤—Å–µ–≥–æ: **{weakest}**; —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ: **{strongest}**.")
    if not bullets:
        bullets.append("- –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–≤–æ–¥–æ–≤.")
    st.markdown("\n".join(bullets))

# ========================= TAB 2: RISK & ACTIONS ==============================
with tab2:
    st.subheader("–†–∏—Å–∫ –∏ –¥–µ–π—Å—Ç–≤–∏—è (—Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ 3 –º–µ—Ç—Ä–∏–∫–∞—Ö)")

    cols_show = [ID_COL, "–†–æ–ª—å", "–ì–æ—Ä–æ–¥", "–ö–æ–≥–æ—Ä—Ç–∞", "PTA", ABOUT_COL]
    # –î–æ–±–∞–≤–∏–º —Ç—Ä–∏ –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    for c in compare_cols:
        coln = f"sim_{c}"
        if coln in data.columns:
            cols_show.append(coln)

    # –ù–∏–∑–∫–∞—è –∫–æ–≥–æ—Ä—Ç–∞ ‚Äî –≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    st.markdown("#### üî¥ –ü—Ä–æ—Ñ–∏–ª–∏ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–ù–∏–∑–∫–∏–π PTA)")
    fix_df = data[data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)"].sort_values("PTA")
    if len(fix_df):
        st.dataframe(fix_df[cols_show].head(30), use_container_width=True, height=360)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (Excel)",
                           data=to_excel_bytes(fix_df[cols_show], "to_fix"),
                           file_name="profiles_to_fix.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ù–µ—Ç –ø—Ä–æ—Ñ–∏–ª–µ–π –≤ –∑–æ–Ω–µ '–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)' –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã.")

    st.markdown("---")

    # –°—Ä–µ–¥–Ω—è—è –∫–æ–≥–æ—Ä—Ç–∞ ‚Äî –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ
    st.markdown("#### üü° –ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–¥ –≤–Ω–∏–º–∞–Ω–∏–µ (–°—Ä–µ–¥–Ω–∏–π PTA)")
    watch_df = data[data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)"].sort_values("PTA")
    if len(watch_df):
        st.dataframe(watch_df[cols_show].head(30), use_container_width=True, height=360)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥ –≤–Ω–∏–º–∞–Ω–∏–µ (Excel)",
                           data=to_excel_bytes(watch_df[cols_show], "to_watch"),
                           file_name="profiles_to_watch.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ù–µ—Ç –ø—Ä–æ—Ñ–∏–ª–µ–π –≤ –∫–æ–≥–æ—Ä—Ç–µ '–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)' –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã.")

    st.markdown("---")

    # –í—ã—Å–æ–∫–∞—è –∫–æ–≥–æ—Ä—Ç–∞ ‚Äî –û–ö (–º–æ–∂–Ω–æ —Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞)
    st.markdown("#### üü¢ –ì–æ—Ç–æ–≤—ã –∫ –∫–ª–∏–µ–Ω—Ç—É (–í—ã—Å–æ–∫–∏–π PTA)")
    ok_df = data[data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–í—ã—Å–æ–∫–∏–π (–û–ö)"].sort_values("PTA", ascending=False)
    if len(ok_df):
        st.dataframe(ok_df[cols_show].head(30), use_container_width=True, height=360)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –≥–æ—Ç–æ–≤—ã—Ö –∫ –∫–ª–∏–µ–Ω—Ç—É (Excel)",
                           data=to_excel_bytes(ok_df[cols_show], "ready"),
                           file_name="profiles_ready.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ù–µ—Ç –ø—Ä–æ—Ñ–∏–ª–µ–π —Å '–í—ã—Å–æ–∫–∏–π (–û–ö)' –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã.")

    st.markdown("---")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–∞–±–æ–π –º–µ—Ç—Ä–∏–∫–∏)
    st.markdown("### üìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    recs = []
    # –∫–∞–∫–∏–µ –∏–∑ —Ç—Ä–µ—Ö –º–µ—Ç—Ä–∏–∫ —Å–ª–∞–±–µ–µ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É
    if sim_cols_present:
        means_map = {METRIC_LABELS[c]: data[f"sim_{c}"].mean() for c in compare_cols}
        if means_map:
            # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é (—Å–ª–∞–±–µ–µ ‚Äî –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            weak_sorted = sorted(means_map.items(), key=lambda x: x[1])
            for metric, val in weak_sorted:
                if metric == "Keyword Fit":
                    recs.append("- **Keyword Fit** –Ω–∏–∑–∫–∏–π ‚Üí —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (—Å–∏–Ω–æ–Ω–∏–º—ã ‚Üí –±–∞–∑–æ–≤—ã–µ —Ñ–æ—Ä–º—ã, –æ—Ç—Å–µ—è—Ç—å –æ–±—â–∏–µ —Å–ª–æ–≤–∞). –î–æ–±–∞–≤–∏—Ç—å 5‚Äì7 —Ç–æ—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –≤ '–û —Å–µ–±–µ'.")
                elif metric == "Task Fit":
                    recs.append("- **Task Fit** –Ω–∏–∑–∫–∏–π ‚Üí –ø—Ä–∏–≤–µ—Å—Ç–∏ '–û —Å–µ–±–µ' –∫ —è–∑—ã–∫—É —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á (–Ω–∞—á–∏–Ω–∞—Ç—å —Å –≥–ª–∞–≥–æ–ª–æ–≤: ¬´–¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É—é¬ª, ¬´–ø—Ä–æ–≤–æ–∂—É¬ª, ¬´–≤–Ω–µ–¥—Ä—è—é¬ª + 2‚Äì3 —Ç–∏–ø–æ–≤—ã—Ö –∫–µ–π—Å–∞).")
                elif metric == "Specialty Fit":
                    recs.append("- **Specialty Fit** –Ω–∏–∑–∫–∏–π ‚Üí —Å–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∫–µ–π—Å–∞–º–∏; —É–±—Ä–∞—Ç—å –æ–±—â–∏–π —à—É–º, –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ—á–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è.")
    # –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º
    share_high = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–í—ã—Å–æ–∫–∏–π (–û–ö)").mean() if len(data) else 0
    share_mid  = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)").mean() if len(data) else 0
    share_low  = (data["–ö–æ–≥–æ—Ä—Ç–∞"] == "–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)").mean() if len(data) else 0
    overall_pta = safe_mean(data["PTA"])

    if overall_pta < TARGET_PTA and not math.isnan(overall_pta):
        recs.append(f"- –°—Ä–µ–¥–Ω–∏–π PTA = {overall_pta:.2f} –Ω–∏–∂–µ —Ü–µ–ª–∏ {TARGET_PTA:.2f} ‚Üí –Ω–∞—á–∞—Ç—å —Å '–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)' –∏ –∑–∞—Ç–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å '–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)'.")
    if share_low > 0.15:
        recs.append("- '–ù–∏–∑–∫–∏–π (–ò—Å–ø—Ä–∞–≤–∏—Ç—å)' > 15% ‚Üí –ø—Ä–æ–≤–µ—Å—Ç–∏ —ç–∫—Å–ø—Ä–µ—Å—Å-–∞—É–¥–∏—Ç –ø—Ä–æ—Ñ–∏–ª–µ–π —Å —à–∞–±–ª–æ–Ω–æ–º '–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å' –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏.")
    if share_mid > 0.30:
        recs.append("- –í—ã—Å–æ–∫–∞—è –¥–æ–ª—è '–°—Ä–µ–¥–Ω–∏–π (–í–Ω–∏–º–∞–Ω–∏–µ)' ‚Üí –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ—Ä–∫—à–æ–ø –ø–æ —Å–∞–º–æ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Ç–µ–∑–∞—É—Ä—É—Å—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.")
    if not recs:
        recs.append("- –£—Ä–æ–≤–µ–Ω—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –µ–∂–µ–º–µ—Å—è—á–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Ç–æ—á–µ—á–Ω—ã–µ –ø—Ä–∞–≤–∫–∏.")
    st.markdown("\n".join(recs))

# ========================= TAB 3: PEOPLE OPS =================================
with tab3:
    st.subheader("–û–ø–µ—Ä–∞—Ü–∏–∏: –Ω–∞–π–º, –æ–±—É—á–µ–Ω–∏–µ, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å")

    # Hiring: –≥–¥–µ PTA –Ω–∏–∑–æ–∫ –∏ –¥–æ–ª—è '–û–ö' –º–∞–ª–∞ ‚Üí —É—Å–∏–ª–∏–≤–∞—Ç—å –Ω–∞–π–º / –Ω–∞—Å—Ç–∞–≤–Ω–∏—á–µ—Å—Ç–≤–æ
    st.markdown("#### Hiring Map ‚Äî –≥–¥–µ —É—Å–∏–ª–∏–≤–∞—Ç—å –Ω–∞–π–º/–Ω–∞—Å—Ç–∞–≤–Ω–∏—á–µ—Å—Ç–≤–æ")
    if "–ì–æ—Ä–æ–¥" in data.columns and len(data):
        by_city = (data.groupby("–ì–æ—Ä–æ–¥")
                        .agg(PTA=("PTA", "mean"),
                             OKshare=("–ö–æ–≥–æ—Ä—Ç–∞", lambda s: (s=="–í—ã—Å–æ–∫–∏–π (–û–ö)").mean()),
                             Count=("PTA", "size"))
                        .reset_index())
        hire_need = by_city[(by_city["PTA"] < 0.55) & (by_city["OKshare"] < 0.50)]
        st.dataframe(hire_need.sort_values(["PTA", "OKshare"]).head(20),
                     use_container_width=True, height=320)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Hiring Map (Excel)",
                           data=to_excel_bytes(hire_need, "hiring_map"),
                           file_name="hiring_map.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥–æ—Ä–æ–¥–∞–º –¥–ª—è Hiring Map.")

    st.markdown("---")

    # Training Plan: –∫–∞–∫–∏–µ –∏–∑ —Ç—Ä–µ—Ö –º–µ—Ç—Ä–∏–∫ —Å–ª–∞–±–µ–µ –≤—Å–µ–≥–æ –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏/–≤—ã–±–æ—Ä–∫–µ
    st.markdown("#### Training Plan ‚Äî —á—Ç–æ –∏–º–µ–Ω–Ω–æ –ø–æ–¥—Ç—è–≥–∏–≤–∞—Ç—å")
    if sim_cols_present:
        train_df = pd.DataFrame({
            "–ú–µ—Ç—Ä–∏–∫–∞": [METRIC_LABELS[c] for c in compare_cols],
            "–°—Ä–µ–¥–Ω–µ–µ": [data[f"sim_{c}"].mean() for c in compare_cols],
        }).sort_values("–°—Ä–µ–¥–Ω–µ–µ")
        st.dataframe(train_df, use_container_width=True, height=280)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å Training Plan (Excel)",
                           data=to_excel_bytes(train_df, "training_plan"),
                           file_name="training_plan.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ù–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ ‚Äî —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è –Ω–µ–ª—å–∑—è.")

    st.markdown("---")

    # Completeness: –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å —Ç—Ä–µ—Ö –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π + '–û —Å–µ–±–µ'
    st.markdown("#### –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª–µ–π (4 –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª—è)")
    key_cols = [ABOUT_COL] + compare_cols
    present_cols = [c for c in key_cols if c in data.columns]
    if present_cols:
        compl = data[present_cols].notna().mean(axis=1)
        compl_df = data[[ID_COL, "–†–æ–ª—å", "–ì–æ—Ä–æ–¥", "PTA", "–ö–æ–≥–æ—Ä—Ç–∞"]].copy()
        compl_df["Completeness"] = compl.values
        st.dataframe(compl_df.sort_values("Completeness").head(30),
                     use_container_width=True, height=320)
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞ –¥–æ–Ω–∞–ø–æ–ª–Ω–µ–Ω–∏–µ (Excel)",
                           data=to_excel_bytes(compl_df.sort_values("Completeness"), "completeness"),
                           file_name="profiles_completeness.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("–ö–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
